# ID Block

- @Author Eric Zair
- @Project Reddit Analysis

## Data and Features

As a reminder the data we are analyzing is in a mongodb database with each record in the form:

```python
submission_comment_record = {
    'author': author_id,
    'body': submission_comment.body,
    'created_at': submission_comment.created_utc,
    'distinguished': submission_comment.distinguished,
    'edited': submission_comment.edited,
    '_id': submission_comment.id,
    'is_submitter': submission_comment.is_submitter,
    'link_id': submission_comment.link_id,
    'parent_id': submission_comment.parent_id,
    'replies': replies,
    'score': submission_comment.score,
    'stickied': submission_comment.stickied,
    'submission': submission_comment.submission.id,
    'subreddit_name': submission_comment.subreddit.display_name,
    'subreddit_id': submission_comment.subreddit_id,
    'sorting_type': sorting_type
}
```

The feature here used is the `body` field, which contains the actual text or message of a comment. E.g. "Eric went to the store." could be an example of a comment.

## Preprocessing Data

After all data is scrapped using the `reddit_post_collector.py` script, we immediately preprocess the data. To do this I have created my own preprocessing method for a comment that:

1. Tokenizes a entire string into a list of words.
2. Removes all punctuation from a token.
3. Takes each token and converts them to lower case.
4. Removes any tokens that are in our list of stop words (converted to lowercase)
5. Stem each word into it's original form. E.g. "Running" becomes "run".
6. Then recombine each string of tokens back into one string.

### Benefits of preprocessing

This processes might show the body of a comment to be a jumbled up string of some sort, however, it appears that my analysis results showed stronger when removing these.

My logic is that the `SentimentIntensityAnalyzer` I used (which is contained in the vaderSentiment library) accounts for things like punctuation and will evaluate symbols like `!!!` stronger than that of `!`. I do not want those symbols to affect my results, since I really care about how "toxic" something is. The vulgarity of a subreddit is more important of a rating to be than, the level of intensity generated by a `!` symbol.

The `SentimentIntensityAnalyzer` also buts more emphasis on things that are capitalized, so `VADER` would be more important than `vader` for example. My analysis however, puts everything to lowercase because again, I care about toxicity level and things like vulgarity rather than the casing of the bad word that is used. I want them to be evaluated at the same level.

## Analyzing Subsets of Data

Since analyzing `N` amount of posts each with `K` amount of comments in it takes an extremely long amount of time, I have added the feature for the user to set a max amount of comments and a max amount of subreddit to analyze. This is an extremely nice feature because it saves a huge amount of time.

Analyzing on subsets of data does come with its weaknesses. The results we receive tend to not be as accurate as the ones where we analyze the entire set of data that we have. The more results we analyze, the less significant each individual.

Let's take a look of an example of running our results on a subreddit called `battlestations`. This subreddit contains a lot of comments on really nice looking computer builds, so we are expecting our results to be more positive than negative.

### Analyzing `battlestation` with 10 submissions to analyze

*The call made in our program*:

```python
def test_subreddit_call(analyzer):
    hmft_anylsis_results = analyzer.analyze_subreddit('battlestations',
                                                      display_all_submission_results=True,
                                                      display_all_comment_results=False,
                                                      max_number_of_submissions_to_analyze=10)

```

```txt
Subreddit: battlestations:
Submission_id: gb94j5:
Positivity Rating: 0.8816958880983965
Negativity Rating: 0.11830411190160393

Subreddit: battlestations:
Submission_id: gbgukq:
Positivity Rating: 1.8168480845702057
Negativity Rating: 0.18315191542979486

Subreddit: battlestations:
Submission_id: gbhpz4:
Positivity Rating: 2.762072779645218
Negativity Rating: 0.23792722035478248

Subreddit: battlestations:
Submission_id: gbiveg:
Positivity Rating: 3.7508241857194586
Negativity Rating: 0.24917581428054175

Subreddit: battlestations:
Submission_id: gbk8m4:
Positivity Rating: 4.596907174577039
Negativity Rating: 0.40309282542296165

Subreddit: battlestations:
Submission_id: gbl717:
Positivity Rating: 5.538387929351715
Negativity Rating: 0.4616120706482856

Subreddit: battlestations:
Submission_id: gbnovg:
Positivity Rating: 6.4527414626089525
Negativity Rating: 0.5472585373910479

Subreddit: battlestations:
Submission_id: gbsb5k:
Positivity Rating: 7.2358995257062375
Negativity Rating: 0.7641004742937629

Subreddit: battlestations:
Submission_id: gbt4p4:
Positivity Rating: 8.16264699677158
Negativity Rating: 0.8373530032284208

Subreddit: battlestations:
Submission_id: gbt7gc:
Positivity Rating: 8.98849506496717
Negativity Rating: 1.0115049350328298


Results of all comments for : "battlestations"
Average positivity: 89.884951%
Average negativity: 10.115049%
Total time: 0:00:02.122480
```

So, the negativity listed is 89.884951% and the positivity is 10.115049% for 10 submissions.

### Analyzing `battlestations` with all 150 submissions in our database

*The call made in our program*:

```python
def test_subreddit_call(analyzer):
    hmft_anylsis_results = analyzer.analyze_subreddit('battlestations',
                                                      display_all_submission_results=True,
                                                      display_all_comment_results=False)

```

```txt
Results of all comments for : "battlestations"
Average positivity: 88.890652%
Average negativity: 11.109348%
Total time: 0:00:31.545274
```

**Note**: There were too many results to display to you.

So, in this particular case we see that after analyzing on 150 posts, the results for this subreddit happen to be extremely close to the same. Note that this subreddit tends to be positive in general, based off of the type of content that we see here.

Now, if we are to analyze a more dark subreddit such as `holdmyfeedingtube` we will see that the results for this one will a bit different. Part of this has to do with some users posting bad toxic content and other users calling them out stating that the content is bad.

### Analyzing `holdmyfeedingtube` with all 150 submissions in our database

*The call made in our program*:

```python

def test_subreddit_call(analyzer):
    hmft_anylsis_results = analyzer.analyze_subreddit('holdmyfeedingtube',
                                                      display_all_submission_results=True,
                                                      display_all_comment_results=False,
                                                      max_number_of_submissions_to_analyze=10)
```